{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"qCY6UbkkI9_N"},"source":["# Style Transfer\n","\n","<img src=\"https://i0.wp.com/chelseatroy.com/wp-content/uploads/2018/12/neural_style_transfer.png?resize=768%2C311&ssl=1\">\n","\n","La idea de este trabajo final es reproducir el siguiente paper:\n","\n","https://arxiv.org/pdf/1508.06576.pdf\n","\n","El objetivo es transferir el estilo de una imagen dada a otra imagen distinta. \n","\n","Como hemos visto en clase, las primeras capas de una red convolucional se activan ante la presencia de ciertos patrones vinculados a detalles muy pequeños.\n","\n","A medida que avanzamos en las distintas capas de una red neuronal convolucional, los filtros se van activando a medida que detectan patrones de formas cada vez mas complejos.\n","\n","Lo que propone este paper es asignarle a la activación de las primeras capas de una red neuronal convolucional (por ejemplo VGG19) la definición del estilo y a la activación de las últimas capas de la red neuronal convolucional, la definición del contenido.\n","\n","La idea de este paper es, a partir de dos imágenes (una que aporte el estilo y otra que aporte el contenido) analizar cómo es la activación de las primeras capas para la imagen que aporta el estilo y cómo es la activación de las últimas capas de la red convolucional para la imagen que aporta el contenido. A partir de esto se intentará sintetizar una imagen que active los filtros de las primeras capas que se activaron con la imagen que aporta el estilo y los filtros de las últimas capas que se activaron con la imagen que aporta el contenido.\n","\n","A este procedimiento se lo denomina neural style transfer.\n","\n","# En este trabajo se deberá leer el paper mencionado y en base a ello, entender la implementación que se muestra a continuación y contestar preguntas sobre la misma.\n","\n","# Una metodología posible es hacer una lectura rápida del paper (aunque esto signifique no entender algunos detalles del mismo) y luego ir analizando el código y respondiendo las preguntas. A medida que se planteen las preguntas, volviendo a leer secciones específicas del paper terminará de entender los detalles que pudieran haber quedado pendientes.\n","\n","Lo primero que haremos es cargar dos imágenes, una que aporte el estilo y otra que aporte el contenido. A tal fin utilizaremos imágenes disponibles en la web."]},{"cell_type":"code","metadata":{"id":"kyHsa2t0SxZi","colab":{"base_uri":"https://localhost:8080/"},"outputId":"ecca708c-855c-4490-aca1-339a66ee9259","executionInfo":{"status":"ok","timestamp":1676726311727,"user_tz":0,"elapsed":1528,"user":{"displayName":"Agustina Resasco","userId":"11553623770358590040"}}},"source":["# Imagen para estilo\n","!wget https://upload.wikimedia.org/wikipedia/commons/5/52/La_noche_estrellada1.jpg\n","\n","# Imagen para contenido\n","!wget https://upload.wikimedia.org/wikipedia/commons/thumb/f/f4/Neckarfront_T%C3%BCbingen_Mai_2017.jpg/775px-Neckarfront_T%C3%BCbingen_Mai_2017.jpg\n","\n","# Creamos el directorio para los archivos de salida\n","!mkdir /content/output"],"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["--2023-02-18 13:18:29--  https://upload.wikimedia.org/wikipedia/commons/5/52/La_noche_estrellada1.jpg\n","Resolving upload.wikimedia.org (upload.wikimedia.org)... 103.102.166.240, 2001:df2:e500:ed1a::2:b\n","Connecting to upload.wikimedia.org (upload.wikimedia.org)|103.102.166.240|:443... connected.\n","HTTP request sent, awaiting response... 200 OK\n","Length: 223725 (218K) [image/jpeg]\n","Saving to: ‘La_noche_estrellada1.jpg’\n","\n","La_noche_estrellada 100%[===================>] 218.48K  --.-KB/s    in 0.007s  \n","\n","2023-02-18 13:18:29 (28.9 MB/s) - ‘La_noche_estrellada1.jpg’ saved [223725/223725]\n","\n","--2023-02-18 13:18:30--  https://upload.wikimedia.org/wikipedia/commons/thumb/f/f4/Neckarfront_T%C3%BCbingen_Mai_2017.jpg/775px-Neckarfront_T%C3%BCbingen_Mai_2017.jpg\n","Resolving upload.wikimedia.org (upload.wikimedia.org)... 103.102.166.240, 2001:df2:e500:ed1a::2:b\n","Connecting to upload.wikimedia.org (upload.wikimedia.org)|103.102.166.240|:443... connected.\n","HTTP request sent, awaiting response... 200 OK\n","Length: 153015 (149K) [image/jpeg]\n","Saving to: ‘775px-Neckarfront_Tübingen_Mai_2017.jpg’\n","\n","775px-Neckarfront_T 100%[===================>] 149.43K  --.-KB/s    in 0.006s  \n","\n","2023-02-18 13:18:30 (26.4 MB/s) - ‘775px-Neckarfront_Tübingen_Mai_2017.jpg’ saved [153015/153015]\n","\n"]}]},{"cell_type":"code","source":["\n","# Creo el directorio para los archivos de salida, priorizando el estilo\n","!mkdir /content/output_estilo\n","\n","# Creo el directorio para los archivos de salida, priorizando el contenido\n","!mkdir /content/output_contenido"],"metadata":{"id":"ikhCX0coy6rQ","executionInfo":{"status":"ok","timestamp":1676726311728,"user_tz":0,"elapsed":4,"user":{"displayName":"Agustina Resasco","userId":"11553623770358590040"}}},"execution_count":2,"outputs":[]},{"cell_type":"code","metadata":{"id":"NIxH20o2eFoc","executionInfo":{"status":"ok","timestamp":1676726316221,"user_tz":0,"elapsed":2124,"user":{"displayName":"Agustina Resasco","userId":"11553623770358590040"}}},"source":["from tensorflow.keras.utils import load_img, save_img, img_to_array\n","#from keras.preprocessing.image import save_img, img_to_array\n","import numpy as np\n","from scipy.optimize import fmin_l_bfgs_b\n","import time\n","import argparse\n","\n","from keras.applications import vgg19\n","from keras import backend as K\n","from pathlib import Path\n","\n","import tensorflow as tf\n","tf.compat.v1.disable_eager_execution()\n","\n","from matplotlib import pyplot as plt"],"execution_count":3,"outputs":[]},{"cell_type":"code","metadata":{"id":"iLkV1bnFl_tK","executionInfo":{"status":"ok","timestamp":1676726378295,"user_tz":0,"elapsed":494,"user":{"displayName":"Agustina Resasco","userId":"11553623770358590040"}}},"source":["# Definimos las imagenes que vamos a utilizar, y el directorio de salida\n","\n","base_image_path = Path(\"/content/775px-Neckarfront_Tübingen_Mai_2017.jpg\")\n","style_reference_image_path = Path(\"/content/La_noche_estrellada1.jpg\")\n","result_prefix = Path(\"/content/output\")\n","iterations = 100"],"execution_count":12,"outputs":[]},{"cell_type":"code","source":["# PRIORIZANDO EL ESTILO\n","# Definimos las imagenes que vamos a utilizar, y el directorio de salida\n","\n","base_image_path = Path(\"/content/775px-Neckarfront_Tübingen_Mai_2017.jpg\")\n","style_reference_image_path = Path(\"/content/La_noche_estrellada1.jpg\")\n","result_prefix = Path(\"/content/output_estilo\")\n","iterations = 100"],"metadata":{"id":"H77NEx76_cPZ","executionInfo":{"status":"ok","timestamp":1676719113453,"user_tz":0,"elapsed":296,"user":{"displayName":"Agustina Resasco","userId":"11553623770358590040"}}},"execution_count":9,"outputs":[]},{"cell_type":"code","source":["#PRIORIZANDO EL CONTENIDO\n","# PRIORIZANDO EL ESTILO\n","# Definimos las imagenes que vamos a utilizar, y el directorio de salida\n","\n","base_image_path = Path(\"/content/775px-Neckarfront_Tübingen_Mai_2017.jpg\")\n","style_reference_image_path = Path(\"/content/La_noche_estrellada1.jpg\")\n","result_prefix = Path(\"/content/output_contenido\")\n","iterations = 100"],"metadata":{"id":"hHkTBeLo_izL","executionInfo":{"status":"ok","timestamp":1676720089289,"user_tz":0,"elapsed":1,"user":{"displayName":"Agustina Resasco","userId":"11553623770358590040"}}},"execution_count":4,"outputs":[]},{"cell_type":"code","source":["# Celda con las nuevas fotos y paths\n","\n","# Definimos las imagenes que vamos a utilizar, y el directorio de salida\n","\n","base_image_path = Path(\"/content/Base_Photo.jpeg\")\n","style_reference_image_path = Path(\"/content/The Kiss.jpg\")\n","\n","!mkdir /content/output_new_example\n","result_prefix = Path(\"/content/output_new_example\")"],"metadata":{"id":"5UOmXwNp70lH","executionInfo":{"status":"ok","timestamp":1676726339559,"user_tz":0,"elapsed":730,"user":{"displayName":"Agustina Resasco","userId":"11553623770358590040"}}},"execution_count":5,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Gz2PeGfpeYzj"},"source":["# 1) En base a lo visto en el paper ¿Qué significan los parámetros definidos en la siguiente celda?\n","\n","Respuesta: El paper hace una diferenciación entre el contenido de la imágen (osea, qué objeto se está representando) y el arte en sí mismo (el componente artístico en terminos de la paleta de colores y el estilo con el que se representan las imágenes - por ejemplo las distintas texturas).\n","\n","En la implementación de la red neuronal, la función de costo tiene dos términos, uno que hace referencia al contenido y otro al estilo. Esto permite regular el 'peso' que se le adjudica a cada componente, con imágenes más fieles a la original cuando se le adjudica mayor peso al contenido e imágenes que claramente representan el arte de la pintura original perdiendo los distintos objetos cuando se aplica mayor énfasis al estilo. \n"]},{"cell_type":"code","metadata":{"id":"P9Dt3aaEmJWS","executionInfo":{"status":"ok","timestamp":1676726386047,"user_tz":0,"elapsed":701,"user":{"displayName":"Agustina Resasco","userId":"11553623770358590040"}}},"source":["total_variation_weight = 0.1\n","style_weight = 10\n","content_weight = 1"],"execution_count":13,"outputs":[]},{"cell_type":"code","source":["# Priorizando el estilo\n","\n","total_variation_weight = 1\n","style_weight = 100\n","content_weight = 0.01"],"metadata":{"id":"t9J3JkIU-yNn","executionInfo":{"status":"ok","timestamp":1676719069929,"user_tz":0,"elapsed":305,"user":{"displayName":"Agustina Resasco","userId":"11553623770358590040"}}},"execution_count":6,"outputs":[]},{"cell_type":"code","source":["# priorizando el contenido\n","\n","total_variation_weight = 1\n","style_weight = 0.1\n","content_weight = 100"],"metadata":{"id":"CJxUEdj3-yYk","executionInfo":{"status":"ok","timestamp":1676720097776,"user_tz":0,"elapsed":308,"user":{"displayName":"Agustina Resasco","userId":"11553623770358590040"}}},"execution_count":5,"outputs":[]},{"cell_type":"code","metadata":{"id":"CQQJOhCVuse6","executionInfo":{"status":"ok","timestamp":1676726388786,"user_tz":0,"elapsed":875,"user":{"displayName":"Agustina Resasco","userId":"11553623770358590040"}}},"source":["# Definimos el tamaño de las imágenes a utilizar\n","width, height = load_img(base_image_path).size\n","img_nrows = 400\n","img_ncols = int(width * img_nrows / height)"],"execution_count":14,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"gg2ct-8agm1E"},"source":["# 2) Explicar qué hace la siguiente celda. En especial las últimas dos líneas de la función antes del return. ¿Por qué?\n","\n","Ayuda: https://keras.io/applications/\n","\n","Respuesta: En esta celda se define una función que toma como argumento el path que lleva a la carpeta que contiene las imágenes. Luego, realiza las siguientes acciones:\n","1) carga la imagen y la adapta al tamaño definido en la celda anterior. 2) transforma la imagen en un array. 3) Le agrega una dimensión. 4) Convierte las imágenes de RGB a BGR (requisito de VGG19) y las normaliza \n"]},{"cell_type":"code","metadata":{"id":"tAkljg4zuzYd","executionInfo":{"status":"ok","timestamp":1676726393520,"user_tz":0,"elapsed":616,"user":{"displayName":"Agustina Resasco","userId":"11553623770358590040"}}},"source":["def preprocess_image(image_path):\n","    img = load_img(image_path, target_size=(img_nrows, img_ncols))\n","    img = img_to_array(img)\n","    img = np.expand_dims(img, axis=0)\n","    img = vgg19.preprocess_input(img)\n","    return img"],"execution_count":15,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"KTf0YDSagt10"},"source":["# 3) Habiendo comprendido lo que hace la celda anterior, explique de manera muy concisa qué hace la siguiente celda. ¿Qué relación tiene con la celda anterior?\n","\n","Respuesta: la celda a continuación hace el camino inverso para poder volver a la imágen original.\n","1) En cada capa de color de la imágen, 'desnormaliza' los valores. 2) Transforma la imágen de BGR a RGB"]},{"cell_type":"code","metadata":{"id":"y5LaTrsAu14z","executionInfo":{"status":"ok","timestamp":1676726394966,"user_tz":0,"elapsed":3,"user":{"displayName":"Agustina Resasco","userId":"11553623770358590040"}}},"source":["def deprocess_image(x):\n","    x = x.reshape((img_nrows, img_ncols, 3))\n","    # Remove zero-center by mean pixel\n","    x[:, :, 0] += 103.939\n","    x[:, :, 1] += 116.779\n","    x[:, :, 2] += 123.68\n","    # 'BGR'->'RGB'\n","    x = x[:, :, ::-1]\n","    x = np.clip(x, 0, 255).astype('uint8')\n","    return x"],"execution_count":16,"outputs":[]},{"cell_type":"code","metadata":{"id":"HYNio09mu4S3","executionInfo":{"status":"ok","timestamp":1676726401301,"user_tz":0,"elapsed":397,"user":{"displayName":"Agustina Resasco","userId":"11553623770358590040"}}},"source":["# get tensor representations of our images\n","# K.variable convierte un numpy array en un tensor, para \n","base_image = K.variable(preprocess_image(base_image_path))\n","style_reference_image = K.variable(preprocess_image(style_reference_image_path))"],"execution_count":18,"outputs":[]},{"cell_type":"code","metadata":{"id":"a1Lbw02Uu--o","executionInfo":{"status":"ok","timestamp":1676726401712,"user_tz":0,"elapsed":2,"user":{"displayName":"Agustina Resasco","userId":"11553623770358590040"}}},"source":["combination_image = K.placeholder((1, img_nrows, img_ncols, 3))"],"execution_count":19,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"RJEi0YI3Uzrm"},"source":["Aclaración:\n","\n","La siguiente celda sirve para procesar las tres imagenes (contenido, estilo y salida) en un solo batch."]},{"cell_type":"code","metadata":{"id":"gGO_jGFfvEbF","executionInfo":{"status":"ok","timestamp":1676726407450,"user_tz":0,"elapsed":416,"user":{"displayName":"Agustina Resasco","userId":"11553623770358590040"}}},"source":["# combine the 3 images into a single Keras tensor\n","input_tensor = K.concatenate([base_image,\n","                              style_reference_image,\n","                              combination_image], axis=0)"],"execution_count":20,"outputs":[]},{"cell_type":"code","metadata":{"id":"tdG59VRavHGB","colab":{"base_uri":"https://localhost:8080/"},"outputId":"94e2a982-d548-40a9-c32f-5d03e8fb6404","executionInfo":{"status":"ok","timestamp":1676726418256,"user_tz":0,"elapsed":9068,"user":{"displayName":"Agustina Resasco","userId":"11553623770358590040"}}},"source":["# build the VGG19 network with our 3 images as input\n","# the model will be loaded with pre-trained ImageNet weights\n","model = vgg19.VGG19(input_tensor=input_tensor,\n","                    weights='imagenet', include_top=False)\n","print('Model loaded.')\n","\n","# get the symbolic outputs of each \"key\" layer (we gave them unique names).\n","outputs_dict = dict([(layer.name, layer.output) for layer in model.layers])"],"execution_count":21,"outputs":[{"output_type":"stream","name":"stdout","text":["Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/vgg19/vgg19_weights_tf_dim_ordering_tf_kernels_notop.h5\n","80134624/80134624 [==============================] - 4s 0us/step\n","Model loaded.\n"]}]},{"cell_type":"markdown","metadata":{"id":"70-vs_jZkKVc"},"source":["# 4) En la siguientes celdas:\n","\n","- ¿Qué es la matriz de Gram?¿Para qué se usa?\n","\n","La matriz de Gram es la representación del estilo (el 'arte') de los features que se obtuvieron de una red neuronal (en este caso VGG19). Para construirla se computan las correlaciones de los feature maps obtenidos a partir de una red neuronal. A partir la correlación de los distintos features se puede inferir cómo estos se combinan para generar los distintos estilos. En este sentido, vamos a poder ver que dos features siempre aparecen juntos, y eso lo vamos a poder transferir a la imágen nueva. \n","\n","\n","- ¿Por qué se permutan las dimensiones de x?\n","\n","Porque para obtener la matriz de Gram hay que multiplicar una matriz por esa misma matriz transpuesta. Esto permite obtener su grado de correlación."]},{"cell_type":"code","metadata":{"id":"K1FODPATvJ1k","executionInfo":{"status":"ok","timestamp":1676726418257,"user_tz":0,"elapsed":4,"user":{"displayName":"Agustina Resasco","userId":"11553623770358590040"}}},"source":["def gram_matrix(x):\n","    features = K.batch_flatten(K.permute_dimensions(x, (2, 0, 1)))\n","    gram = K.dot(features, K.transpose(features))\n","    return gram"],"execution_count":22,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"vBQkKFY0Rbx-"},"source":["# 5) Losses:\n","\n","Explicar qué mide cada una de las losses en las siguientes tres celdas.\n","\n","Rta: Tal como fue definido en el primer punto, la función de costo para hacer transferencia de estilo está definida por dos componentes, el primero es del de estilo (que emplea la matriz de gram definida en la celda anterior), y el segundo es el de contenido.\n","\n"]},{"cell_type":"code","metadata":{"id":"1-Gt0ahWvN6q","executionInfo":{"status":"ok","timestamp":1676726418258,"user_tz":0,"elapsed":4,"user":{"displayName":"Agustina Resasco","userId":"11553623770358590040"}}},"source":["def style_loss(style, combination):\n","    assert K.ndim(style) == 3\n","    assert K.ndim(combination) == 3\n","    S = gram_matrix(style)\n","    C = gram_matrix(combination)\n","    channels = 3\n","    size = img_nrows * img_ncols\n","    return K.sum(K.square(S - C)) / (4.0 * (channels ** 2) * (size ** 2))"],"execution_count":23,"outputs":[]},{"cell_type":"code","metadata":{"id":"XCqnju5RvQCo","executionInfo":{"status":"ok","timestamp":1676726418258,"user_tz":0,"elapsed":4,"user":{"displayName":"Agustina Resasco","userId":"11553623770358590040"}}},"source":["def content_loss(base, combination):\n","    return K.sum(K.square(combination - base))\n"],"execution_count":24,"outputs":[]},{"cell_type":"code","metadata":{"id":"udEp5h31vRnY","executionInfo":{"status":"ok","timestamp":1676726418673,"user_tz":0,"elapsed":6,"user":{"displayName":"Agustina Resasco","userId":"11553623770358590040"}}},"source":["def total_variation_loss(x):\n","    assert K.ndim(x) == 4\n","    a = K.square(\n","        x[:, :img_nrows - 1, :img_ncols - 1, :] - x[:, 1:, :img_ncols - 1, :])\n","    b = K.square(\n","        x[:, :img_nrows - 1, :img_ncols - 1, :] - x[:, :img_nrows - 1, 1:, :])\n","    return K.sum(K.pow(a + b, 1.25))\n"],"execution_count":25,"outputs":[]},{"cell_type":"code","metadata":{"id":"-65vcinbvTZ0","executionInfo":{"status":"ok","timestamp":1676726419085,"user_tz":0,"elapsed":417,"user":{"displayName":"Agustina Resasco","userId":"11553623770358590040"}}},"source":["# Armamos la loss total\n","loss = K.variable(0.0)\n","layer_features = outputs_dict['block5_conv2']\n","base_image_features = layer_features[0, :, :, :]\n","combination_features = layer_features[2, :, :, :]\n","loss = loss + content_weight * content_loss(base_image_features,\n","                                            combination_features)\n","\n","feature_layers = ['block1_conv1', 'block2_conv1',\n","                  'block3_conv1', 'block4_conv1',\n","                  'block5_conv1']\n","for layer_name in feature_layers:\n","    layer_features = outputs_dict[layer_name]\n","    style_reference_features = layer_features[1, :, :, :] \n","    combination_features = layer_features[2, :, :, :]\n","    sl = style_loss(style_reference_features, combination_features)\n","    loss = loss + (style_weight / len(feature_layers)) * sl\n","loss = loss + total_variation_weight * total_variation_loss(combination_image)"],"execution_count":26,"outputs":[]},{"cell_type":"code","metadata":{"id":"pbz4n1OhvV2K","executionInfo":{"status":"ok","timestamp":1676726421296,"user_tz":0,"elapsed":439,"user":{"displayName":"Agustina Resasco","userId":"11553623770358590040"}}},"source":["grads = K.gradients(loss, combination_image)\n","\n","\n","outputs = [loss]\n","if isinstance(grads, (list, tuple)):\n","    outputs += grads\n","else:\n","    outputs.append(grads)\n","\n","f_outputs = K.function([combination_image], outputs)"],"execution_count":27,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"1JbydbOaVcvU"},"source":["# 6) Explique el propósito de las siguientes tres celdas. ¿Qué hace la función fmin_l_bfgs_b? ¿En qué se diferencia con la implementación del paper? ¿Se puede utilizar alguna alternativa?\n","\n","Respuesta:\n","\n","En el paper se utiliza descenso de gradiente tradicional para minimizar la función de costo, pero la convergencia va a demorar más tiempo. \n","Por el contratio, la función fmin_l_bfgs_b, es un método de segundo orden (estima la derivada de la derivada) que es capaz de alcanzar el mínimo de forma más eficiente.Específicamente L-BFGS es una extensión del algoritmo que le permite lidiar con un número grande de parámetros. La b final viene de 'boxed', en el que se pueden setear los límites superiores e inferiores del dominio. "]},{"cell_type":"code","metadata":{"id":"zVE1_qemvZeN","executionInfo":{"status":"ok","timestamp":1676726423951,"user_tz":0,"elapsed":2,"user":{"displayName":"Agustina Resasco","userId":"11553623770358590040"}}},"source":["def eval_loss_and_grads(x):\n","    x = x.reshape((1, img_nrows, img_ncols, 3))\n","    outs = f_outputs([x])\n","    loss_value = outs[0]\n","    if len(outs[1:]) == 1:\n","        grad_values = outs[1].flatten().astype('float64')\n","    else:\n","        grad_values = np.array(outs[1:]).flatten().astype('float64')\n","    return loss_value, grad_values\n","\n","# this Evaluator class makes it possible\n","# to compute loss and gradients in one pass\n","# while retrieving them via two separate functions,\n","# \"loss\" and \"grads\". This is done because scipy.optimize\n","# requires separate functions for loss and gradients,\n","# but computing them separately would be inefficient."],"execution_count":28,"outputs":[]},{"cell_type":"code","metadata":{"id":"Qbl9roIgvdb1","executionInfo":{"status":"ok","timestamp":1676726426192,"user_tz":0,"elapsed":2,"user":{"displayName":"Agustina Resasco","userId":"11553623770358590040"}}},"source":["class Evaluator(object):\n","\n","    def __init__(self):\n","        self.loss_value = None\n","        self.grads_values = None\n","\n","    def loss(self, x):\n","        assert self.loss_value is None\n","        loss_value, grad_values = eval_loss_and_grads(x)\n","        self.loss_value = loss_value\n","        self.grad_values = grad_values\n","        return self.loss_value\n","\n","    def grads(self, x):\n","        assert self.loss_value is not None\n","        grad_values = np.copy(self.grad_values)\n","        self.loss_value = None\n","        self.grad_values = None\n","        return grad_values"],"execution_count":29,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Sb0yOEl-WOE6"},"source":["# 7) Ejecute la siguiente celda y observe las imágenes de salida en cada iteración.\n","\n","A medida que se va produciendo el entrenamiento, se puede observar como la imágen de entrada va obteniendo características del estilo que queremos reproducir (el cambio se ve más claro en el cielo, en donde se empiezan a formar trazos circulares, y va cambiando la paleta de colores)."]},{"cell_type":"code","metadata":{"id":"n31YBwCVvhAI","colab":{"base_uri":"https://localhost:8080/","height":1000,"output_embedded_package_id":"1Caqd3yr2_UqbckNgwzmiHMf35rvU92NR"},"outputId":"1815711f-8d96-47a7-e594-43a61d64e7a0","executionInfo":{"status":"ok","timestamp":1676727214137,"user_tz":0,"elapsed":785898,"user":{"displayName":"Agustina Resasco","userId":"11553623770358590040"}}},"source":["evaluator = Evaluator()\n","\n","# run scipy-based optimization (L-BFGS) over the pixels of the generated image\n","# so as to minimize the neural style loss\n","x = preprocess_image(base_image_path)\n","\n","for i in range(iterations):\n","    print('Start of iteration', i)\n","    start_time = time.time()\n","    x, min_val, info = fmin_l_bfgs_b(evaluator.loss, x.flatten(),\n","                                     fprime=evaluator.grads, maxfun=20)\n","    print('Current loss value:', min_val)\n","    # save current generated image\n","    img = deprocess_image(x.copy())\n","    fname = result_prefix / ('output_at_iteration_%d.png' % i)\n","    save_img(fname, img)\n","    # imprimo la imagen\n","    plt.imshow(img, interpolation='nearest')\n","    plt.show()\n","    end_time = time.time()\n","    print('Image saved as', fname)\n","    print('Iteration %d completed in %ds' % (i, end_time - start_time))"],"execution_count":30,"outputs":[{"output_type":"display_data","data":{"text/plain":"Output hidden; open in https://colab.research.google.com to view."},"metadata":{}}]},{"cell_type":"markdown","metadata":{"id":"SkiJtofbWWy1"},"source":["# 8) Generar imágenes para distintas combinaciones de pesos de las losses. Explicar las diferencias. (Adjuntar las imágenes generadas como archivos separados.)\n","\n","Respuesta: priorizando el estilo se le da más preponderancia a la paleta de colores y el tipo de trazo, mientras que priorizando el contenido se le da más importancia a los objetos que se muestran en la imagen.\n","\n"]},{"cell_type":"markdown","source":["# Priorizando el estilo"],"metadata":{"id":"isfMNCbVzedR"}},{"cell_type":"code","source":["evaluator = Evaluator()\n","\n","# run scipy-based optimization (L-BFGS) over the pixels of the generated image\n","# so as to minimize the neural style loss\n","x = preprocess_image(base_image_path)\n","\n","for i in range(iterations):\n","    print('Start of iteration', i)\n","    start_time = time.time()\n","    x, min_val, info = fmin_l_bfgs_b(evaluator.loss, x.flatten(),\n","                                     fprime=evaluator.grads, maxfun=20)\n","    print('Current loss value:', min_val)\n","    # save current generated image\n","    img = deprocess_image(x.copy())\n","    fname = result_prefix / ('output_at_iteration_%d.png' % i)\n","    save_img(fname, img)\n","    # imprimo la imagen\n","    plt.imshow(img, interpolation='nearest')\n","    plt.show()\n","    end_time = time.time()\n","    print('Image saved as', fname)\n","    print('Iteration %d completed in %ds' % (i, end_time - start_time))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000,"output_embedded_package_id":"1leZLXRR9RdD6o1uowi2AleRvqzDd2bt4"},"id":"bbWvzDSbzVHA","executionInfo":{"status":"ok","timestamp":1676719948548,"user_tz":0,"elapsed":787867,"user":{"displayName":"Agustina Resasco","userId":"11553623770358590040"}},"outputId":"e61e316e-4407-42ad-aab6-834c0a35ba40"},"execution_count":25,"outputs":[{"output_type":"display_data","data":{"text/plain":"Output hidden; open in https://colab.research.google.com to view."},"metadata":{}}]},{"cell_type":"markdown","source":["#Priorizando el contenido"],"metadata":{"id":"6ZJa8zTTzm5R"}},{"cell_type":"code","source":["# Reinicio el kernel antes de correr esta celda, corro todo salvo la celda anterior para re-entrenar\n","\n","evaluator = Evaluator()\n","\n","# run scipy-based optimization (L-BFGS) over the pixels of the generated image\n","# so as to minimize the neural style loss\n","x = preprocess_image(base_image_path)\n","\n","for i in range(iterations):\n","    print('Start of iteration', i)\n","    start_time = time.time()\n","    x, min_val, info = fmin_l_bfgs_b(evaluator.loss, x.flatten(),\n","                                     fprime=evaluator.grads, maxfun=20)\n","    print('Current loss value:', min_val)\n","    # save current generated image\n","    img = deprocess_image(x.copy())\n","    fname = result_prefix / ('output_at_iteration_%d.png' % i)\n","    save_img(fname, img)\n","    # imprimo la imagen\n","    plt.imshow(img, interpolation='nearest')\n","    plt.show()\n","    end_time = time.time()\n","    print('Image saved as', fname)\n","    print('Iteration %d completed in %ds' % (i, end_time - start_time))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000,"output_embedded_package_id":"1tRpyo9oBYWWIjoyzPi6i98Lm3efF0qgn"},"id":"A-nsEl64zq-p","executionInfo":{"status":"ok","timestamp":1676720927312,"user_tz":0,"elapsed":796690,"user":{"displayName":"Agustina Resasco","userId":"11553623770358590040"}},"outputId":"c4c67b85-0887-40e2-a514-0badf2d4089c"},"execution_count":21,"outputs":[{"output_type":"display_data","data":{"text/plain":"Output hidden; open in https://colab.research.google.com to view."},"metadata":{}}]},{"cell_type":"markdown","source":["\n","# 9) Cambiar las imágenes de contenido y estilo por unas elegidas por usted. Adjuntar el resultado.\n","\n","Respuesta:"],"metadata":{"id":"mAkev0MzzVoA"}},{"cell_type":"code","source":["evaluator = Evaluator()\n","\n","# run scipy-based optimization (L-BFGS) over the pixels of the generated image\n","# so as to minimize the neural style loss\n","x = preprocess_image(base_image_path)\n","\n","for i in range(iterations):\n","    print('Start of iteration', i)\n","    start_time = time.time()\n","    x, min_val, info = fmin_l_bfgs_b(evaluator.loss, x.flatten(),\n","                                     fprime=evaluator.grads, maxfun=20)\n","    print('Current loss value:', min_val)\n","    # save current generated image\n","    img = deprocess_image(x.copy())\n","    fname = result_prefix / ('output_at_iteration_%d.png' % i)\n","    save_img(fname, img)\n","    # imprimo la imagen\n","    plt.imshow(img, interpolation='nearest')\n","    plt.show()\n","    end_time = time.time()\n","    print('Image saved as', fname)\n","    print('Iteration %d completed in %ds' % (i, end_time - start_time))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000,"output_embedded_package_id":"1yLO1P4yS1rM8-VQcNMkRtMTxxYtzSFhF"},"id":"HUFeJwq954ln","executionInfo":{"status":"ok","timestamp":1676726185496,"user_tz":0,"elapsed":1702418,"user":{"displayName":"Agustina Resasco","userId":"11553623770358590040"}},"outputId":"dccaa0c7-b284-437e-e3a3-38bc9f0a7f61"},"execution_count":57,"outputs":[{"output_type":"display_data","data":{"text/plain":"Output hidden; open in https://colab.research.google.com to view."},"metadata":{}}]}]}